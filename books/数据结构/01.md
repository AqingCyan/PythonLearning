## 时间复杂度与大'O'记法
> 代码在不同机器上运算时间不同，但执行基本运算数量大体相同。因此，我们可以用基本计算数量来描述程序算法的执行效率。

以下两种算法的结果一样，但计算数量不一样，因此，方法一所用时长明显大于方法二
```python
# 如果a+b+c=1000，且a^2+b^2=c^2（abc皆为自然数），求出a、b、c可能的组合？

# a
# b
# c
# 方法1：暴力枚举法，把所有的数字遍历，求出来
import time

start_time = time.time()
for a in range(0, 1001):
    for b in range(0,1001):
        for c in range(0,1001):
            if a + b + c == 1000 and a**2 + b**2 == c**2:
                print("a, b, c: %d, %d, %d" %(a, b, c))
end_time = time.time()
print("times:%ds，now finished" %(end_time - start_time))
```
```python
# 方法2：如果知道a与b，c就是1000-a-b
import time

start_time = time.time()
for a in range(0, 1001):
    for b in range(0,1001):
        c = 1000 - a - b # 去掉了C的循环遍历，直接计算它
        if a + b + c == 1000 and a**2 + b**2 == c**2:
            print("a, b, c: %d, %d, %d" %(a, b, c))
end_time = time.time()
print("times:%.02fs，now finished" %(end_time - start_time))
```
### 我们把基本计算数量总和叫做时间复杂度
### 对于算法的时间效率，我们可以用**大O记法**表示
- 大O记法：对于单调的整函数f，如果存在一个整函数g和实常数`c>0`，使得对于充分大的n总有`f(n)<c*g(n)`，就说函数g是一个渐近函数（忽略常数），记为`f(n)=O(g(n))`。也就是说，在趋向于无穷的极限意义下，函数f的增长速度受到函数g的约束，亦即函数f与函数g的特征相似。
- 时间复杂度：假设存在函数g，使得算法A处理规模为n的问题示例所用时间为`T(n)=O(g(n))`，则称`O(g(n))`为算法A的渐近时间复杂度，简称复杂度，记为`T(n)`
### 如何理解大O记法
对于算法特别具体的细致分析虽然好，但是在实践中的实际价值有限。对于算法的时间性质和空间性质，最重要的是其数量级和趋势，这些事分析算法的主要部分。而计量算法基本操作数量的规模函数中那些常亮因子可以忽略不计。例如，可以认为`3n^2`和`100n^2`属于同一个量级，如果两个算法处理同样规模实例的代价分别为这两个函数，就认为它们的效率差不多，都为`n^2`级。
## 最坏时间复杂度
分析算法时，存在几种可能的考虑：
- 算法完成工作最少需要多少基本操作，即为**最优时间复杂度**
- 算法完成工作最多需要多少基本操作，即为**最坏时间复杂度**
- 算法完成工作平均需要多少基本操作，即为**平均时间复杂度**

对于最优时间复杂度，其价值不大，因为它没有提供什么有用信息，其反映的只是最乐观的最理想的情况，没有参考价值。

对于最坏时间复杂度，提供了一种保证，表明算法在此种程度的基本操作数中一定能完成工作。

对于平均时间复杂度，是对算法的一个全面评价，因此它完整全面的反映了这个算法的性质。但另一方面，这种衡量没有保证，不是每个计算都能在这个基本操作内完成。而且对于平均情况的计算，也会因为应用算法的实例分布可能并不均匀而难以计算。

**因此，我们主要关注算法的最坏情况，亦即最坏时间复杂度。**
## 时间复杂度的计算规则
1. 基本操作，即只有常数项，认为其时间复杂度为O(1)。
2. 顺序结构，时间复杂度按**加法**进行计算。
3. 循环结构，时间复杂度按**乘法**进行计算。
4. 分支结构，时间复杂度取最大值。
5. 判断一个算法的效率时，往往只需要关注操作数量的最高次项，其他次要项和常数项可以忽略。
6. 在没有特殊说明时，我们所分析的算法时间复杂度都是指**最坏时间复杂度*。